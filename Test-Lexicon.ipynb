{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of fnsa.lexicon failed: Traceback (most recent call last):\n",
      "  File \"/Users/rflagg/anaconda3/envs/fsa/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ImportError: cannot import name 'EXTRACTED_ENTITY_LEX'\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fnsa.lexicon import Lexicon, prepare\n",
    "from fnsa.util import *\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "sentences = load_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexicon = Lexicon(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fe', '+', 4, 5, -1, False), ('if', 'rev', 8, 9, -1, False), ('if', 'mod', 5, 6, -1, False), ('if', 'mod', 6, 7, -1, False), ('lm', '+', 5, 6, -1, False), ('lm', '-', 8, 9, -1, False), ('xe', 'org', 1, 2, -1, True), ('xe', 'org', 4, 5, -1, True)]\n",
      "1. The Group's operative EBIT will probably be negative.\n",
      "   The [Group/xe:org] 's operative [EBIT/fe:+] [will/if:mod] [probably/if:mod] be [negative/if:rev] .\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(sentences[:1]):\n",
    "    doc = lexicon(sentence)\n",
    "    show(doc, index=(i+1), include_text=True)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group --> xe/org\n",
      "probably --> if/mod\n",
      "EBIT --> fe/+\n",
      "negative --> if/rev\n",
      "will --> if/mod\n"
     ]
    }
   ],
   "source": [
    "for lex, category, start, end, index, acceptable in doc.user_data['entries']:\n",
    "    print(\"%s --> %s/%s\" % (doc[start:end], lex, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = self.nlp(text)\n",
    "prepare(doc, self.lexicons)\n",
    "for e in doc.ents: \n",
    "    store_match(doc, EXTRACTED_ENTITY_LEX, e.label_.lower()[:3], e.start, e.end, -1, e.label_ in ACCEPTABLE_TYPES)\n",
    "self.match(doc)\n",
    "self.merge(doc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earnings per share ( EPS ) amounted to EUR0 .98 , up from the loss of EUR0 .02 .\n",
      "Earnings per share ( EPS ) amounted to EUR0 .98 , up from the loss of EUR0 .02 .\n",
      "Earnings per share ( EPS ) amounted to EUR0 .98 , up from the loss of EUR0 .02 .\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "sentence = 'Earnings per share ( EPS ) amounted to EUR0 .98 , up from the loss of EUR0 .02 .'\n",
    "doc = nlp(sentence)\n",
    "print(sentence)\n",
    "prepare(doc, lexicon.lexicons)\n",
    "print(doc)\n",
    "#print(json.dumps(doc.user_data, indent=4, sort_keys=True))\n",
    "#print(doc.user_data)\n",
    "lexicon.match(doc)\n",
    "print(doc)\n",
    "lexicon.merge(doc)\n",
    "#print(doc)\n",
    "\n",
    "\n",
    "#print(json.dumps(doc.user_data, indent=4, sort_keys=True))\n",
    "#print(doc.user_data)\n",
    "\n",
    "#annotations = annotate(doc)\n",
    "#print(\" \".join(annotations))\n",
    "#for token in doc: print(\"[%s/%s:%s]\" % (token.text, token._.lex, token._.category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earnings per share ( EPS ) amounted to EUR0 .98 , up from the loss of EUR0 .02 .\n",
      " [Earnings per share/fe:+] ( [EPS/fe:+] ) amounted to [EUR0/xe:org] .98 , [up/dr:+] from the [loss/fe:-] of [EUR0/xe:org] .02 .\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Earnings per share ( EPS ) amounted to EUR0 .98 , up from the loss of EUR0 .02 .'\n",
    "doc = lexicon(sentence)\n",
    "show(doc, include_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('._.', 'lex', 70, None): 'xe',\n",
       " 'en2scope': {},\n",
       " ('._.', 'lex', 0, None): 'fe',\n",
       " ('._.', 'category', 50, None): '+',\n",
       " ('._.', 'lex', 62, None): 'fe',\n",
       " ('._.', 'category', 0, None): '+',\n",
       " ('._.', 'category', 70, None): 'org',\n",
       " 'fi_matched': False,\n",
       " 'fe_matched': True,\n",
       " ('._.', 'lex', 39, None): 'xe',\n",
       " ('._.', 'category', 62, None): '-',\n",
       " 'entries': {('dr', '+', 11, 12, -1, False),\n",
       "  ('fe', '+', 0, 3, -1, False),\n",
       "  ('fe', '+', 4, 5, -1, False),\n",
       "  ('fe', '-', 14, 15, -1, False),\n",
       "  ('xe', 'org', 8, 9, -1, True),\n",
       "  ('xe', 'org', 16, 17, -1, True)},\n",
       " 'lm_matched': True,\n",
       " 'if_matched': False,\n",
       " ('._.', 'category', 39, None): 'org',\n",
       " 'dr_matched': True,\n",
       " ('._.', 'lex', 21, None): 'fe',\n",
       " ('._.', 'lex', 50, None): 'dr',\n",
       " ('._.', 'category', 21, None): '+'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:fsa]",
   "language": "python",
   "name": "conda-env-fsa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
